{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Important for multiprocessing.\n",
    "import torch\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import get_3d_subplot_axs\n",
    "from plot import get_figsize, set_figsize\n",
    "\n",
    "default_w, default_h = get_figsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from gridsearch import experiment, load_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create NARMA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dataset as ds\n",
    "\n",
    "u_train, y_train = ds.NARMA(sample_len = 2000)\n",
    "u_test, y_test = ds.NARMA(sample_len = 3000)\n",
    "dataset = [u_train, y_train, u_test, y_test]\n",
    "ds.dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Waxman graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matrix import waxman\n",
    "from plot import scatter_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matrix import euclidean\n",
    "\n",
    "# We need names for the distance functions to select them from a pandas\n",
    "# dataframe later.\n",
    "euc = euclidean\n",
    "def inv(x, y): return 1/euclidean(x, y)\n",
    "def inv_squared(x, y): return 1/euclidean(x, y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Waxman visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for z_frac in [0.0, 0.5, 1.0]:\n",
    "    G = waxman(n=200, alpha=1.0, beta=1.0, z_frac=z_frac)\n",
    "    scatter_3d(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Waxman performance with increasing fraction of 3d nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['waxman']\n",
    "params['dist_function'] = [inv]\n",
    "params['hidden_nodes'] = np.arange(20, 90, 10)\n",
    "params['z_frac'] = np.arange(0.0, 1.2, 0.2)\n",
    "params['directed'] = [True, False]\n",
    "waxman_nrmse_df = experiment(esn_nrmse, params, runs=20)\n",
    "waxman_nrmse_df.to_pickle('experiments/waxman_nrmse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'waxman_nrmse_df' not in locals():\n",
    "    waxman_nrmse_df = load_experiment('experiments/waxman_nrmse.pkl')\n",
    "\n",
    "df = waxman_nrmse_df.loc[waxman_nrmse_df['directed'] == False]\n",
    "groupby = ['hidden_nodes', 'z_frac']\n",
    "\n",
    "axes    = ['hidden_nodes', 'z_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "zlim    = [(0.40, 0.80), (0.40, 0.80)]\n",
    "azim    = [160, 160]\n",
    "title   = 'Increasing fraction of 3d nodes'\n",
    "\n",
    "plot_df_trisurf(df=df, groupby=groupby, axes=axes, agg=agg, azim=azim, zlim=zlim, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A hypothesis as to what we're seeing from the *min* plot is that there is little  \n",
    "noticeable difference with increasing *z_frac*. Additionally, we do not see the  \n",
    "expected performance increase when adding more hidden nodes to the reservoir.  \n",
    "\n",
    "An initial for why more nodes does not matter is that there is a cap on what the  \n",
    "reservoir may be capable of learning with only positive weights, especially when  \n",
    "the network is fully connected. In fact, more nodes makes it more likely for the  \n",
    "network to be \"unstable\", explaining the higher performance variance seen in the  \n",
    "leftmost plot. Since all weights are positive: does the scaling for spectral  \n",
    "radius purposes have to be tighter?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Distribution of reservoir weights with different distance functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The first thing we want to address is how the distribution of weights differ  \n",
    "with different distance functions for the generated Waxman graph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ESN import ESN\n",
    "from plot import plot_esn_weight_hist\n",
    "\n",
    "bins = 40\n",
    "params = {\n",
    "    'hidden_nodes': 150,\n",
    "}\n",
    "\n",
    "plt.title('Reference ESN')\n",
    "plot_esn_weight_hist(params, n_bins=bins, show=True)\n",
    "\n",
    "set_figsize(14, 6)\n",
    "\n",
    "params = {\n",
    "    'directed': False,\n",
    "    'w_res_type': 'waxman',\n",
    "}\n",
    "\n",
    "hidden_nodes = [50, 150, 150, 150]\n",
    "dist_functions = [euc, euc, inv, inv_squared]\n",
    "titles = ['50 nodes euc', '150 nodes euc', '150 nodes inv', '150 nodes inv^2']\n",
    "\n",
    "for z_frac in [0.0, 1.0]:\n",
    "    fig, axs = plt.subplots(1, 4)\n",
    "\n",
    "    params['z_frac'] = z_frac\n",
    "    plt.suptitle('z_frac:' + str(z_frac))\n",
    "\n",
    "    for i in range(len(axs)):\n",
    "        params['hidden_nodes'] = hidden_nodes[i]\n",
    "        params['dist_function'] = dist_functions[i]\n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.set_title(titles[i])\n",
    "        plot_esn_weight_hist(params, n_bins=bins, ax=ax, show=False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "set_figsize(default_w, default_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We see the clear difference between the functions *d*, *1/d* and *1/d^*; we can  \n",
    "almost see the functions in the distributions themselves.  \n",
    "\n",
    "When the weight function moves from d to 1/d to 1/d, we see that we are shifting  \n",
    "the probability distribution towards many lower weights, with just a few big  \n",
    "ones, which is as expected.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Waxman performance with changing weight/distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['waxman']\n",
    "params['z_frac'] = np.arange(0.0, 1.2, 0.2)\n",
    "params['hidden_nodes'] = np.arange(20, 90, 10)\n",
    "params['dist_function'] = [euc, inv, inv_squared]\n",
    "waxman_dist_df = experiment(esn_nrmse, params, runs=20)\n",
    "waxman_dist_df.to_pickle('experiments/waxman_dist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'waxman_dist_df' not in locals():\n",
    "    waxman_dist_df = load_experiment('experiments/waxman_dist.pkl')\n",
    "\n",
    "waxman_dist_df['dist_function'] = waxman_dist_df['dist_function'].apply(\n",
    "    lambda f: f.__name__ if not isinstance(f, str) else f\n",
    ")\n",
    "\n",
    "euc_df = waxman_dist_df.loc[waxman_dist_df['dist_function'] == euc.__name__]\n",
    "inv_df = waxman_dist_df.loc[waxman_dist_df['dist_function'] == inv.__name__]\n",
    "inv_squared_df = waxman_dist_df.loc[waxman_dist_df['dist_function'] == inv_squared.__name__]\n",
    "\n",
    "groupby = ['hidden_nodes', 'z_frac']\n",
    "axes    = ['hidden_nodes', 'z_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "titles  = ['euc', 'inv', 'inv^2']\n",
    "labels  = ['euc', 'inv', 'inv^2']\n",
    "zlim    = (0.3, 1.0)\n",
    "azim    = 110\n",
    "\n",
    "for i, df in enumerate([euc_df, inv_df, inv_squared_df]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, agg=agg, azim=azim, zlim=zlim, title=titles[i])\n",
    "\n",
    "ax = get_3d_subplot_axs(1)[0]\n",
    "show = [False, False, True]\n",
    "for i, df in enumerate([euc_df, inv_df, inv_squared_df]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, azim=azim, zlim=zlim,\n",
    "                    title='min for all dist functions', agg=['min'], ax=ax, label=labels[i],\n",
    "                    show=show[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It does seem like the different distance functions may all achieve about the  \n",
    "same performance in terms of error rate on NARMA10, giving a slight edge to the  \n",
    "inverse functions. However, the latter ones also introduce the instability we  \n",
    "see disappear when we use a minimum aggregation instead. The weights in general  \n",
    "are _smaller_, as can be seen in the weight distribution plots. First thoughts:  \n",
    "can this be remedied with input scalings? It is clear that _z\\_frac_ has little  \n",
    "impact on performance, so let's change it to input scaling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['waxman']\n",
    "params['input_scaling'] = np.arange(0.1, 2.1, 0.1)\n",
    "params['hidden_nodes'] = np.arange(20, 90, 10)\n",
    "params['dist_function'] = [euc, inv, inv_squared]\n",
    "waxman_is_df = experiment(esn_nrmse, params, runs=20)\n",
    "waxman_is_df.to_pickle('experiments/waxman_is.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_mc\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['waxman']\n",
    "params['input_scaling'] = np.arange(0.1, 2.1, 0.1)\n",
    "params['hidden_nodes'] = [80]\n",
    "params['dist_function'] = [euc, inv, inv_squared]\n",
    "waxman_is_mc_df = experiment(esn_mc, params, runs=20)\n",
    "waxman_is_mc_df.to_pickle('experiments/waxman_is_mc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'waxman_is_df' not in locals():\n",
    "    waxman_is_df = load_experiment('experiments/waxman_is.pkl')\n",
    "\n",
    "waxman_is_df['dist_function'] = waxman_is_df['dist_function'].apply(\n",
    "    lambda f: f.__name__ if not isinstance(f, str) else f\n",
    ")\n",
    "\n",
    "euc_df = waxman_is_df.loc[waxman_is_df['dist_function'] == euc.__name__]\n",
    "inv_df = waxman_is_df.loc[waxman_is_df['dist_function'] == inv.__name__]\n",
    "inv_squared_df = waxman_is_df.loc[waxman_is_df['dist_function'] == inv_squared.__name__]\n",
    "\n",
    "groupby = ['hidden_nodes', 'input_scaling']\n",
    "axes    = ['hidden_nodes', 'input_scaling', 'esn_nrmse']\n",
    "agg     = ['min']\n",
    "titles  = ['euc', 'inv', 'inv^2']\n",
    "zlim    = (0.5, 0.7)\n",
    "azim    = 20\n",
    "\n",
    "for i, df in enumerate([euc_df, inv_df, inv_squared_df]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, agg=agg, azim=azim, zlim=zlim, title=titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'waxman_is_mc_df' not in locals():\n",
    "    waxman_is_mc_df = load_experiment('experiments/waxman_is_mc.pkl')\n",
    "\n",
    "waxman_is_mc_df['dist_function'] = waxman_is_mc_df['dist_function'].apply(\n",
    "    lambda f: f.__name__ if not isinstance(f, str) else f\n",
    ")\n",
    "\n",
    "euc_df = waxman_is_mc_df.loc[waxman_is_mc_df['dist_function'] == euc.__name__]\n",
    "inv_df = waxman_is_mc_df.loc[waxman_is_mc_df['dist_function'] == inv.__name__]\n",
    "inv_squared_df = waxman_is_mc_df.loc[waxman_is_mc_df['dist_function'] == inv_squared.__name__]\n",
    "\n",
    "labels = ['euc', 'inv', 'inv^2']\n",
    "plt.title('STM (MC) - 80 hidden nodes')\n",
    "plt.xlabel('Input scaling')\n",
    "plt.ylabel('STM (MC)')\n",
    "\n",
    "for i, df in enumerate([euc_df, inv_df, inv_squared_df]):\n",
    "    grouped_df = df.groupby(['input_scaling']).mean().reset_index()\n",
    "    plt.plot(grouped_df['input_scaling'], grouped_df['esn_mc'], label=labels[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Input scaling seems to have a quite big impact on the different distance  \n",
    "functions. In fact, 1/d^2 has a minimum NRMSE with correct input scaling of 0.5,  \n",
    "which is quite a lot lower than the original distance function d.  \n",
    "\n",
    "In the STM plot, we see that 1d^2 consistently has better memory performance  \n",
    "than the other distance functions, even before changing the input scaling. That  \n",
    "much. An analysis of the lyapunov spectrum could prove interesting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Can we see any patterns if we look the output weights of the network for tests  \n",
    "of increasing memory capacity?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from metric import memory_capacity\n",
    "from plot import scatter_3d\n",
    "\n",
    "params = {\n",
    "    'w_res_type': 'waxman',\n",
    "    'hidden_nodes': 80,\n",
    "    'dist_function': inv_squared,\n",
    "    'input_scaling': 0.1,\n",
    "}\n",
    "\n",
    "esn = ESN(**params)\n",
    "mc = memory_capacity(esn)\n",
    "print('Memory capacity:', mc)\n",
    "\n",
    "for i in range(3, 9):\n",
    "    weights = esn.w_outs[i].abs().data.numpy()\n",
    "    weights /= weights.max()\n",
    "    title = 'Hidden weights for STM length: ' + str(i)\n",
    "    scatter_3d(esn.G, title=title, cols=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I see no concernable pattern, which is perhaps as expected from a fully  \n",
    "connected network.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The question remains: what is the difference that makes the inverted functions  \n",
    "increasingly performant on NARMA/memory? Are the internal node activations  \n",
    "relevant?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from metric import evaluate_esn\n",
    "\n",
    "# For comparison to a default network.\n",
    "params = { 'hidden_nodes': 80 }\n",
    "esn = ESN(**params)\n",
    "nrmse = evaluate_esn(ds.dataset, esn)\n",
    "plt.title('Reference NRMSE: ' + str(nrmse))\n",
    "plt.plot(esn.X)\n",
    "plt.show()\n",
    "\n",
    "# With different distance functions.\n",
    "dist_functions = [euc, inv, inv_squared]\n",
    "params = {\n",
    "    'w_res_type': 'waxman',\n",
    "    'hidden_nodes': 80,\n",
    "    'input_scaling': 0.1,\n",
    "}\n",
    "\n",
    "for f in dist_functions:\n",
    "    params['dist_function'] = f\n",
    "    esn = ESN(**params)\n",
    "    nrmse = evaluate_esn(ds.dataset, esn)\n",
    "\n",
    "    plt.title(f.__name__ + ' NRMSE: ' + str(nrmse))\n",
    "    plt.plot(esn.X)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note: this creates a whole new network every time instead of re-using the  \n",
    "existing network but changing the weighting scheme, as to try to understand the  \n",
    "whole picture.  \n",
    "\n",
    "From running this a few times, I notice that the times when the network simply  \n",
    "does not work at all, the root cause is that a big majority of the network nodes  \n",
    "are either *all positive* or *all negative*, there is no balance.  \n",
    "\n",
    "There is a tendency here: the networks that seem to perform well also seem to  \n",
    "resemble the default first ESN network in terms of \"look\", but not so in the  \n",
    "magnitude of the activations -- which is lowered by the spectral radius. This  \n",
    "seems to indicate that the initial spectral radius of the waxman networks are  \n",
    "quite a lot higher than that of default initializations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Moving waxman performance towards Echo State Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Recall the results we got for the original Waxman graph for the 1/d distance  \n",
    "function:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'waxman_dist_df' not in locals():\n",
    "    waxman_dist_df = load_experiment('experiments/waxman_dist.pkl')\n",
    "\n",
    "waxman_dist_df['dist_function'] = waxman_dist_df['dist_function'].apply(\n",
    "    lambda f: f.__name__ if not isinstance(f, str) else f\n",
    ")\n",
    "\n",
    "inv_df = waxman_dist_df.loc[waxman_dist_df['dist_function'] == inv.__name__]\n",
    "\n",
    "groupby = ['hidden_nodes', 'z_frac']\n",
    "axes    = ['hidden_nodes', 'z_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "labels  = ['euc', 'inv', 'inv^2']\n",
    "zlim    = (0.3, 1.0)\n",
    "azim    = 110\n",
    "\n",
    "plot_df_trisurf(df=inv_df, groupby=groupby, axes=axes, agg=agg, azim=azim, zlim=zlim, title='inv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will attempt to make the performance of the Waxman graph equivalent to that  \n",
    "of the Echo State Network by:  \n",
    "\n",
    "* Introducing negative weights\n",
    "* Making the graph directed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Increasing fraction of negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['waxman']\n",
    "params['dist_function'] = [inv]\n",
    "params['z_frac'] = [1.0]\n",
    "params['hidden_nodes'] = np.arange(20, 90, 10)\n",
    "params['sign_frac'] = np.arange(0.0, 0.55, 0.05)\n",
    "params['directed'] = [True, False]\n",
    "waxman_sign_df = experiment(esn_nrmse, params, runs=20)\n",
    "waxman_sign_df.to_pickle('experiments/waxman_sign.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'waxman_sign_df' not in locals():\n",
    "    waxman_sign_df = load_experiment('experiments/waxman_sign.pkl')\n",
    "\n",
    "undirected_df = waxman_sign_df.loc[waxman_sign_df['directed'] == False]\n",
    "directed_df = waxman_sign_df.loc[waxman_sign_df['directed'] == True]\n",
    "\n",
    "groupby = ['hidden_nodes', 'sign_frac']\n",
    "axes    = ['hidden_nodes', 'sign_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "title   = 'Increasing fraction of negative weights'\n",
    "zlim    = (0.3, 1.0)\n",
    "azim    = 70\n",
    "\n",
    "plot_df_trisurf(df=undirected_df, groupby=groupby, axes=axes,\n",
    "                agg=agg, azim=azim, zlim=zlim, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Directed Waxman graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'Effect of directedness'\n",
    "\n",
    "plot_df_trisurf(df=directed_df, groupby=groupby, axes=axes,\n",
    "                agg=agg, azim=azim, zlim=zlim, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Comparison to Echo State Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = np.arange(20, 90, 10)\n",
    "waxman_esn_df = experiment(esn_nrmse, params, runs=20)\n",
    "waxman_esn_df.to_pickle('experiments/waxman_default_esn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'waxman_esn_df' not in locals():\n",
    "    waxman_esn_df = load_experiment('experiments/waxman_default_esn.pkl')\n",
    "\n",
    "waxman_esn_df_max = waxman_esn_df.copy()\n",
    "waxman_esn_df_max['sign_frac'] = 0.5\n",
    "waxman_esn_df_min = waxman_esn_df.copy()\n",
    "waxman_esn_df_min['sign_frac'] = 0.0\n",
    "waxman_esn_df = pd.concat([waxman_esn_df_max, waxman_esn_df_min])\n",
    "\n",
    "labels  = ['+Negative weights', '+Directed', 'Echo State Network']\n",
    "show    = [False, False, True]\n",
    "azim    = 45\n",
    "elev    = 20\n",
    "\n",
    "ax = get_3d_subplot_axs(1)[0]\n",
    "ax.invert_yaxis()\n",
    "for i, df in enumerate([undirected_df, directed_df, waxman_esn_df]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, azim=azim, elev=elev,\n",
    "                    zlim=zlim, title='min', agg=['min'], ax=ax, label=labels[i],\n",
    "                    show=show[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Adding the possibility of having negative weights makes for a big difference,  \n",
    "especially when also combined with a directed network. In fact, we end up with  \n",
    "performance that very closely resembles that of ESNs at the end:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undirected = undirected_df.loc[undirected_df['sign_frac'] == 0.5]\n",
    "directed = directed_df.loc[directed_df['sign_frac'] == 0.5]\n",
    "esn = waxman_esn_df.loc[waxman_esn_df['sign_frac'] == 0.5]\n",
    "\n",
    "labels = ['Undirected', 'Directed', 'Echo State Network']\n",
    "\n",
    "for i, df in enumerate([undirected, directed, esn]):\n",
    "    df = df.groupby(['hidden_nodes', 'sign_frac']).min().reset_index()\n",
    "    plt.plot(df['hidden_nodes'], df['esn_nrmse'], label=labels[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dale et al. investigates this a bit in their paper: «It then becomes clear  \n",
    "that how weights are structured and directed, controlling information flow,  \n",
    "has a greater affect on quality of the network. This supports similar results  \n",
    "using hierarchical networks, where structure and number of parameters also  \n",
    "significantly impact performance [6].»  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lastly, for the similarly performing networks in the previous graph, their  \n",
    "weight distributions look like (exemplified with the undirected graph, as their  \n",
    "distributions will be the same, except a directed graph would be symmetric):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_vector_hist, plot_esn_weight_hist\n",
    "from ESN import ESN\n",
    "\n",
    "bins = 200\n",
    "hidden_nodes = 400\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = hidden_nodes\n",
    "plt.title('Echo State Network reservoir weight distribution')\n",
    "plot_esn_weight_hist(params, n_bins=bins, m=20.0, show=True)\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = 'waxman'\n",
    "params['dist_function'] = inv\n",
    "params['z_frac'] = 1.0\n",
    "params['hidden_nodes'] = hidden_nodes\n",
    "params['sign_frac'] = 0.5\n",
    "params['directed'] = False\n",
    "esn = ESN(**params)\n",
    "M = esn.w_res.data.numpy()\n",
    "\n",
    "# Masking to remove diagonal (i.e. 0-elements) of reservoir weights.\n",
    "M = M[~np.eye(M.shape[0], dtype=bool)].reshape(M.shape[0], -1)\n",
    "\n",
    "weights = M.flatten()\n",
    "plt.title('Waxman graph reservoir weight distribution (network)')\n",
    "plot_vector_hist(weights, n_bins=bins, m=4.0, show=True)\n",
    "\n",
    "weights = M[0].flatten()\n",
    "plt.title('Waxman graph reservoir weight distribution (single node)')\n",
    "plot_vector_hist(weights, n_bins=bins, m=4.0, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First thoughts: does this perhaps fit some known distribution (perhaps something  \n",
    "similar to a power law)?  \n",
    "\n",
    "Now: does this distribution also scale as well with increasing hidden nodes as  \n",
    "the Echo State Network?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "hidden_nodes = np.arange(20, 260, 10)\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['waxman']\n",
    "params['dist_function'] = [inv]\n",
    "params['z_frac'] = [1.0]\n",
    "params['hidden_nodes'] = hidden_nodes\n",
    "params['sign_frac'] = [0.5]\n",
    "params['directed'] = [True]\n",
    "waxman_dist_hn_df = experiment(esn_nrmse, params, runs=20)\n",
    "waxman_dist_hn_df.to_pickle('experiments/waxman_dist_hn.pkl')\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = hidden_nodes\n",
    "esn_hn_df = experiment(esn_nrmse, params, runs=20)\n",
    "esn_hn_df.to_pickle('experiments/esn_hn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'waxman_dist_hn_df' not in locals():\n",
    "    waxman_dist_hn_df = load_experiment('experiments/waxman_dist_hn.pkl')\n",
    "\n",
    "if 'esn_hn_df' not in locals():\n",
    "    esn_hn_df = load_experiment('experiments/esn_hn.pkl')\n",
    "\n",
    "gdf = waxman_dist_hn_df.groupby(['hidden_nodes', 'w_res_type']).mean().reset_index()\n",
    "plt.plot(gdf['hidden_nodes'], gdf['esn_nrmse'], label='Modified Waxman graph')\n",
    "\n",
    "gdf = esn_hn_df.groupby(['hidden_nodes']).mean().reset_index()\n",
    "plt.plot(gdf['hidden_nodes'], gdf['esn_nrmse'], label='Echo State Network')\n",
    "\n",
    "plt.xlabel('Hidden nodes')\n",
    "plt.ylabel('NRMSE')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "So it seems that this symmetric weight distribution performs reasonably  \n",
    "equivalent to the standard ESN. Does it provide an additional robustness? \n",
    "\n",
    "It should not for dead nodes, as with a global connectivity, this is equivalent  \n",
    "to simply removing the node (i.e. decrementing the amount of hidden nodes).  \n",
    "\n",
    "What about sporadically firing nodes, or nodes that constantly produce noise?  \n",
    "\n",
    "I found little interesting in an introductory study of the difference in  \n",
    "robustness attributed to the difference in weight distributions. I might look  \n",
    "deeper into it later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lattice/tiling experiments (sq, rect, hex, tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plots of lattices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ESN import ESN\n",
    "from plot import plot_lattice\n",
    "\n",
    "set_figsize(14, 6)\n",
    "\n",
    "esn_square = ESN(hidden_nodes=25, w_res_type='tetragonal')\n",
    "esn_hex = ESN(hidden_nodes=25, w_res_type='hexagonal')\n",
    "esn_tri = ESN(hidden_nodes=25, w_res_type='triangular')\n",
    "esn_rect = ESN(hidden_nodes=25, w_res_type='rectangular', rect_ratio=2.0)\n",
    "\n",
    "G_square = esn_square.G\n",
    "G_hex = esn_hex.G\n",
    "G_tri = esn_tri.G\n",
    "G_rect = esn_rect.G\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "ax1, ax2, ax3, ax4 = axs[0, 0], axs[0, 1], axs[1, 0], axs[1, 1]\n",
    "plot_lattice(G_square, title='Square', ax=ax1, show=False)\n",
    "plot_lattice(G_hex, title='Hexagonal', ax=ax2, show=False)\n",
    "plot_lattice(G_tri, title='Triangular', ax=ax3, show=False)\n",
    "plot_lattice(G_rect, title='Rectangular', ax=ax4, show=True)\n",
    "\n",
    "set_figsize(default_w, default_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Growing neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ESN import ESN\n",
    "from plot import plot_lattice\n",
    "from matrix import grow_neighborhoods\n",
    "\n",
    "set_figsize(14, 6)\n",
    "\n",
    "esn_sq = ESN(hidden_nodes=25, w_res_type='tetragonal')\n",
    "G_sq = esn_sq.G\n",
    "titles = ['\"Exponential\" growth', 'Default growth']\n",
    "\n",
    "for n_plt in [0, 1]:\n",
    "    _G_sq = G_sq.copy()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    ax1, ax2, ax3, ax4 = axs[0, 0], axs[0, 1], axs[1, 0], axs[1, 1]\n",
    "    axs = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "    for i, ax in enumerate(axs):\n",
    "        plot_lattice(_G_sq, title='Square', ax=ax, neigh_color=True, show=False)\n",
    "\n",
    "        # The second time around we don't \"exponentially\" grow the neighborhood,\n",
    "        # but instead only use the original adjacency matrix to grow the\n",
    "        # neighborhood `l` times.\n",
    "        if n_plt == 0:\n",
    "            grow_neighborhoods(_G_sq, dist_function=inv)\n",
    "        else:\n",
    "            _G_sq = G_sq.copy()\n",
    "            grow_neighborhoods(_G_sq, dist_function=inv, l=i+1)\n",
    "\n",
    "    plt.suptitle(titles[n_plt])\n",
    "\n",
    "set_figsize(default_w, default_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [9, 16, 25, 36, 49, 64, 81]\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "params['grow_neigh'] = list(range(1, 9))\n",
    "params['dist_function'] = [inv]\n",
    "lattice_grow_df = experiment(esn_nrmse, params)\n",
    "lattice_grow_df.to_pickle('experiments/lattice_grow_neigh.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'lattice_grow_df' not in locals():\n",
    "    lattice_grow_df = load_experiment('experiments/lattice_grow_neigh.pkl')\n",
    "\n",
    "groupby = ['hidden_nodes', 'grow_neigh']\n",
    "axes    = ['hidden_nodes', 'grow_neigh', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "titles  = ['Square', 'Hexagonal', 'Triangular']\n",
    "zlim    = (0.5, 0.8)\n",
    "azim    = -60\n",
    "elev    = 20\n",
    "\n",
    "for i, w_res_type in enumerate(['tetragonal', 'hexagonal', 'triangular']):\n",
    "    df = lattice_grow_df.loc[lattice_grow_df['w_res_type'] == w_res_type]\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, agg=agg, azim=azim, elev=elev,\n",
    "                    zlim=zlim, title=titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is a definite performance penalty with increasing sizes of node  \n",
    "neighborhood.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_figsize(14, 6)\n",
    "\n",
    "params = {\n",
    "    'w_res_type': 'tetragonal',\n",
    "    'hidden_nodes': 14*14,\n",
    "    'dist_function': inv,\n",
    "    'grow_neigh': 0,\n",
    "    'readout': 'pinv',\n",
    "}\n",
    "\n",
    "esn = ESN(**params)\n",
    "nrmse = evaluate_esn(ds.dataset, esn, plot=True)\n",
    "print('NRMSE', nrmse )\n",
    "\n",
    "set_figsize(default_w, default_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [9, 16, 25, 36, 49, 64, 81]\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "nrmse_df = experiment(esn_nrmse, params)\n",
    "nrmse_df.to_pickle('experiments/lattice_nrmse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'nrmse_df' not in locals():\n",
    "    nrmse_df = load_experiment('experiments/lattice_nrmse.pkl')\n",
    "\n",
    "grouped_df = nrmse_df.groupby(['hidden_nodes', 'w_res_type']).mean().reset_index()\n",
    "\n",
    "tetragonal = grouped_df.loc[grouped_df['w_res_type'] == 'tetragonal']\n",
    "hexagonal = grouped_df.loc[grouped_df['w_res_type'] == 'hexagonal']\n",
    "triangular = grouped_df.loc[grouped_df['w_res_type'] == 'triangular']\n",
    "\n",
    "plt.plot(tetragonal['hidden_nodes'], tetragonal['esn_nrmse'], label='sq')\n",
    "plt.plot(hexagonal['hidden_nodes'], hexagonal['esn_nrmse'], label='hex')\n",
    "plt.plot(triangular['hidden_nodes'], triangular['esn_nrmse'], label='tri')\n",
    "\n",
    "plt.legend(fancybox=False, loc='upper right', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel('NRMSE')\n",
    "plt.xlabel('Hidden nodes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice STM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Measuring the STM (MC) of lattices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_mc\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [9, 16, 25, 36, 49, 64, 81]\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "mc_df = experiment(esn_mc, params)\n",
    "mc_df.to_pickle('experiments/lattice_mc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'mc_df' not in locals():\n",
    "    mc_df = load_experiment('experiments/lattice_mc.pkl')\n",
    "\n",
    "grouped_df = mc_df.groupby(['hidden_nodes', 'w_res_type']).mean().reset_index()\n",
    "\n",
    "tetragonal = grouped_df.loc[grouped_df['w_res_type'] == 'tetragonal']\n",
    "hexagonal = grouped_df.loc[grouped_df['w_res_type'] == 'hexagonal']\n",
    "triangular = grouped_df.loc[grouped_df['w_res_type'] == 'triangular']\n",
    "\n",
    "plt.plot(tetragonal['hidden_nodes'], tetragonal['esn_mc'], label='sq')\n",
    "plt.plot(hexagonal['hidden_nodes'], hexagonal['esn_mc'], label='hex')\n",
    "plt.plot(triangular['hidden_nodes'], triangular['esn_mc'], label='tri')\n",
    "\n",
    "plt.legend(fancybox=False, loc='upper right', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel('MC')\n",
    "plt.xlabel('Hidden nodes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Is there some pattern in the STM in lattices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First: how does the recall of the network look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from metric import memory_capacity\n",
    "from plot import plot_lattice\n",
    "\n",
    "params = {\n",
    "    'w_res_type': 'hexagonal',\n",
    "    'hidden_nodes': 49,\n",
    "    'input_scaling': 0.1,\n",
    "    'periodic': False,\n",
    "}\n",
    "\n",
    "esn = ESN(**params)\n",
    "mc = memory_capacity(esn)\n",
    "print('Memory capacity:', mc)\n",
    "\n",
    "plt.title(f'Hexagonal lattice memory capacity for {esn.hidden_nodes} hidden nodes')\n",
    "plt.xlabel('Signal delay')\n",
    "plt.ylabel('Recall ability')\n",
    "plt.plot(esn.mcs, marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There was no pattern for the positions of high weighted hidden nodes for the  \n",
    "Waxman graphs, what about highly regular structures/networks?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3, int(mc)):\n",
    "    weights = esn.w_outs[i].abs().data.numpy()\n",
    "    weights /= weights.max()\n",
    "    title = 'Hidden weights for STM length: ' + str(i)\n",
    "    plot_lattice(esn.G, title=title, cols=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*An important note here: this works quite a bit worse if the input distribution  \n",
    "is fixed; the uniform distribution is crucial here.*  \n",
    "\n",
    "Quite interesting! A lot of the memory capacity seems to be due to the edges of  \n",
    "the lattice, seemingly because it is aperiodic. Making the graph periodic tanks  \n",
    "the memory capacity quite a little bit, which is investigated a little bit  \n",
    "further below.  \n",
    "\n",
    "Additionally, big weights in the output layer are often surrounded by other big  \n",
    "weights, which is an interesting indication of the flow of information in the  \n",
    "network.  \n",
    "\n",
    "Lastly, there is not necessarsily anything indicating that clusters of weights  \n",
    "used to recall n is close to weights used to recall n-1, which is slightly  \n",
    "surprising.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What about the activations of the seemingly most important hidden nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_figsize(12, 5)\n",
    "\n",
    "length = 200\n",
    "n_max = 3\n",
    "n_min = 3\n",
    "\n",
    "for i in range(3, 6):\n",
    "    weights = esn.w_outs[i].abs().data.numpy()\n",
    "    min_elems = np.argpartition(weights, n_min)[:n_min]\n",
    "    max_elems = np.argpartition(weights, -n_max)[-n_max:]\n",
    "\n",
    "    min_activations = esn.X_train[:length, min_elems]\n",
    "    max_activations = esn.X_train[:length, max_elems]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    plt.suptitle('Activations for nodes of biggest w_out weights for STM length: ' + str(i))\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_ylim(-0.08, 0.08)\n",
    "\n",
    "    ax1.plot(min_activations)\n",
    "    ax2.plot(max_activations)\n",
    "\n",
    "set_figsize(default_w, default_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice input scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_mc\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [25, 36, 49, 64, 81]\n",
    "params['input_scaling'] = np.insert(np.arange(0.05, 2.05, 0.05), 0, 0.01, axis=0)\n",
    "params['w_res_type'] = [None, 'tetragonal', 'hexagonal', 'triangular']\n",
    "waxman_is_df = experiment(esn_mc, params)\n",
    "is_df.to_pickle('experiments/lattice_input_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'is_df' not in locals():\n",
    "    is_df = load_experiment('experiments/lattice_input_scaling.pkl')\n",
    "\n",
    "reference_esn = is_df.loc[is_df['w_res_type'].isnull()]\n",
    "tetragonal = is_df.loc[is_df['w_res_type'] == 'tetragonal']\n",
    "hexagonal = is_df.loc[is_df['w_res_type'] == 'hexagonal']\n",
    "triangular = is_df.loc[is_df['w_res_type'] == 'triangular']\n",
    "\n",
    "groupby = ['hidden_nodes', 'input_scaling']\n",
    "axes    = ['input_scaling', 'hidden_nodes', 'esn_mc']\n",
    "agg     = ['mean', 'max']\n",
    "titles  = ['Reference ESN', 'Square', 'Hexagonal', 'Triangular']\n",
    "zlims   = [(5, 50)] + [(5, 20)]*3\n",
    "azim    = 70\n",
    "\n",
    "for i, df in enumerate([reference_esn, tetragonal, hexagonal, triangular]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, agg=agg, zlim=zlims[i], title=titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Using a rectangular lattice instead of square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [25, 36, 49, 64, 81]\n",
    "params['w_res_type'] = ['rectangular']\n",
    "params['rect_ratio'] = np.arange(0.1, 3.1, 0.1)\n",
    "rect_df = experiment(esn_nrmse, params)\n",
    "rect_df.to_pickle('experiments/lattice_rect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'rect_df' not in locals():\n",
    "    rect_df = load_experiment('experiments/lattice_rect.pkl')\n",
    "\n",
    "groupby = ['hidden_nodes', 'rect_ratio']\n",
    "axes    = ['hidden_nodes', 'rect_ratio', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "titles  = title = 'Effect of rectangular lattice'\n",
    "zlim    = (0.5, 0.62)\n",
    "azim    = 40\n",
    "\n",
    "plot_df_trisurf(df=rect_df, groupby=groupby, axes=axes, agg=agg, azim=azim, zlim=zlim, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Periodic lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_mc\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [25, 36, 49, 64, 81]\n",
    "params['periodic'] = [True, False]\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "periodic_df = experiment(esn_mc, params)\n",
    "periodic_df.to_pickle('experiments/periodic_lattice.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'periodic_df' not in locals():\n",
    "    periodic_df = load_experiment('experiments/periodic_lattice.pkl')\n",
    "\n",
    "gdf = periodic_df.groupby(['hidden_nodes', 'periodic', 'w_res_type']).mean().reset_index()\n",
    "\n",
    "from collections import defaultdict\n",
    "dfs = defaultdict(lambda: [])\n",
    "\n",
    "plt.title('Periodic lattices')\n",
    "plt.ylabel('MC')\n",
    "plt.xlabel('Hidden nodes')\n",
    "colors = ['green', 'red', 'blue']\n",
    "\n",
    "for c, l in enumerate(['tetragonal' , 'hexagonal', 'triangular']):\n",
    "    dfs[l].append(gdf.loc[(gdf['w_res_type'] == l) & (gdf['periodic'] == False)])\n",
    "    dfs[l].append(gdf.loc[(gdf['w_res_type'] == l) & (gdf['periodic'] == True)])\n",
    "\n",
    "    for i, p in enumerate(['aperiodic', 'periodic']):\n",
    "        x = dfs[l][i]['hidden_nodes']\n",
    "        y = dfs[l][i]['esn_mc']\n",
    "        label = l + ' ' + p\n",
    "        linestyle = '-' if i == 0 else '--'\n",
    "        plt.plot(x, y, label=label, linestyle=linestyle, color=colors[c])\n",
    "\n",
    "plt.legend(fancybox=False, loc='lower right', bbox_to_anchor=(1.0, 0.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice with a fraction of negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esn = ESN(hidden_nodes=25, w_res_type='hexagonal', sign_frac=0.5)\n",
    "plot_lattice(esn.G, edge_color=True, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['hidden_nodes'] = [25, 36, 49, 64, 81]\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "params['sign_frac'] = np.arange(0.0, 0.55, 0.05)\n",
    "lattice_sign_df = experiment(esn_nrmse, params)\n",
    "lattice_sign_df.to_pickle('experiments/lattice_sign.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'lattice_sign_df' not in locals():\n",
    "    lattice_sign_df = load_experiment('experiments/lattice_sign.pkl')\n",
    "\n",
    "tetragonal = lattice_sign_df.loc[lattice_sign_df['w_res_type'] == 'tetragonal']\n",
    "hexagonal = lattice_sign_df.loc[lattice_sign_df['w_res_type'] == 'hexagonal']\n",
    "triangular = lattice_sign_df.loc[lattice_sign_df['w_res_type'] == 'triangular']\n",
    "\n",
    "groupby = ['hidden_nodes', 'sign_frac']\n",
    "axes    = ['hidden_nodes', 'sign_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "zlim    = (0.55, 0.7)\n",
    "azim    = -50\n",
    "titles  = ['tetragonal', 'hexagonal', 'triangular']\n",
    "\n",
    "for i, df in enumerate([tetragonal, hexagonal, triangular]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, azim=azim, agg=agg, zlim=zlim, title=titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "No difference is obtained by setting some edges to have negative weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice with a fraction of directed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esn = ESN(hidden_nodes=25, w_res_type='hexagonal', dir_frac=0.5)\n",
    "plot_lattice(esn.G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "params['hidden_nodes'] = [25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225]\n",
    "params['dir_frac'] = np.arange(0.0, 1.1, 0.1)\n",
    "lattice_dir_df = experiment(esn_nrmse, params, runs=50)\n",
    "lattice_dir_df.to_pickle('experiments/lattice_dir.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_df_trisurf\n",
    "\n",
    "if 'lattice_dir_df' not in locals():\n",
    "    lattice_dir_df = load_experiment('experiments/lattice_dir.pkl')\n",
    "\n",
    "tetragonal = lattice_dir_df.loc[lattice_dir_df['w_res_type'] == 'tetragonal']\n",
    "hexagonal = lattice_dir_df.loc[lattice_dir_df['w_res_type'] == 'hexagonal']\n",
    "triangular = lattice_dir_df.loc[lattice_dir_df['w_res_type'] == 'triangular']\n",
    "\n",
    "groupby = ['hidden_nodes', 'dir_frac']\n",
    "axes    = ['hidden_nodes', 'dir_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "zlim    = (0.25, 0.7)\n",
    "azim    = 45\n",
    "titles  = ['tetragonal', 'hexagonal', 'triangular']\n",
    "\n",
    "for i, df in enumerate([tetragonal, hexagonal, triangular]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, azim=azim, agg=agg, zlim=zlim, title=titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are below the strictly linear regime of NARMA10! That is interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lattice negative weights+directed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import esn_nrmse\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = ['tetragonal', 'hexagonal', 'triangular']\n",
    "params['hidden_nodes'] = [100]\n",
    "params['dir_frac'] = np.arange(0.0, 1.1, 0.1)\n",
    "params['sign_frac'] = np.arange(0.0, 0.55, 0.05)\n",
    "lattice_neg_dir_df = experiment(esn_nrmse, params, runs=20)\n",
    "lattice_neg_dir_df.to_pickle('experiments/lattice_neg_dir.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'lattice_neg_dir_df' not in locals():\n",
    "    lattice_neg_dir_df = load_experiment('experiments/lattice_neg_dir.pkl')\n",
    "\n",
    "tetragonal = lattice_neg_dir_df.loc[lattice_neg_dir_df['w_res_type'] == 'tetragonal']\n",
    "hexagonal = lattice_neg_dir_df.loc[lattice_neg_dir_df['w_res_type'] == 'hexagonal']\n",
    "triangular = lattice_neg_dir_df.loc[lattice_neg_dir_df['w_res_type'] == 'triangular']\n",
    "\n",
    "groupby = ['sign_frac', 'dir_frac']\n",
    "axes    = ['sign_frac', 'dir_frac', 'esn_nrmse']\n",
    "agg     = ['mean', 'min']\n",
    "zlim    = (0.5, 0.65)\n",
    "azim    = 45\n",
    "titles  = ['tetragonal', 'hexagonal', 'triangular']\n",
    "\n",
    "for i, df in enumerate([tetragonal, hexagonal, triangular]):\n",
    "    plot_df_trisurf(df=df, groupby=groupby, axes=axes, azim=azim, agg=agg, zlim=zlim, title=titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Spectral radius with directed lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import evaluate_esn\n",
    "from ESN import ESN\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = 'tetragonal'\n",
    "params['hidden_nodes'] = 144\n",
    "\n",
    "params['dir_frac'] = 0.0\n",
    "while True:\n",
    "    undir_esn = ESN(**params)\n",
    "    undir_nrmse = evaluate_esn(ds.dataset, undir_esn)\n",
    "    if undir_nrmse < 0.55:\n",
    "        break\n",
    "\n",
    "params['dir_frac'] = 1.0\n",
    "while True:\n",
    "    dir_esn = ESN(**params)\n",
    "    dir_nrmse = evaluate_esn(ds.dataset, dir_esn)\n",
    "    if dir_nrmse < 0.35:\n",
    "        break\n",
    "\n",
    "pickle.dump(dir_esn, open('models/dir_esn.pkl', 'wb'))\n",
    "pickle.dump(undir_esn, open('models/undir_esn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_esn = pickle.load(open('models/dir_esn.pkl', 'rb'))\n",
    "undir_esn = pickle.load(open('models/undir_esn.pkl', 'rb'))\n",
    "\n",
    "print('NRMSE:')\n",
    "print(' undirected:', undir_nrmse)\n",
    "print(' directed:  ', dir_nrmse)\n",
    "\n",
    "print()\n",
    "print('Original spectral radius')\n",
    "print(' undirected:', undir_esn.org_spectral_radius)\n",
    "print(' directed:  ', dir_esn.org_spectral_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Huh! The directed square lattice with 144 hidden nodes is as good as the Echo  \n",
    "State Networks of the same size. This is surprising and promising. Perhaps it is  \n",
    "necessary to design physical reservoirs in simulation first, if one is to  \n",
    "consider the flow of information as such?  \n",
    "\n",
    "Do the activations look wildly different between directed and undirected graphs?  \n",
    "For example, is the directed graph perhaps able to reach the nonlinear part of  \n",
    "tanh?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 100\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "plt.suptitle('Activations for an undirected vs. directed lattice')\n",
    "\n",
    "ax1.plot(undir_esn.X[undir_esn.washout:undir_esn.washout+l])\n",
    "ax1.set_title('Undirected')\n",
    "\n",
    "ax2.plot(dir_esn.X[dir_esn.washout:dir_esn.washout+l])\n",
    "ax2.set_title('Directed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is difficult to differentiate the two: this seems to be a common occurrence.  \n",
    "\n",
    "Is there perhaps a correlation between the spectral radius of the original  \n",
    "adjacency matrix (before scaling), and the NRMSE performance of the lattice?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from metric import evaluate_esn\n",
    "from ESN import ESN\n",
    "\n",
    "params = OrderedDict()\n",
    "params['w_res_type'] = 'tetragonal'\n",
    "params['hidden_nodes'] = 144\n",
    "params['dir_frac'] = 1.0\n",
    "\n",
    "nrmses = []\n",
    "srs = []\n",
    "for i in range(100):\n",
    "    esn = ESN(**params)\n",
    "    nrmse = evaluate_esn(ds.dataset, esn)\n",
    "    nrmses.append(nrmse)\n",
    "    srs.append(esn.org_spectral_radius)\n",
    "\n",
    "pickle.dump(nrmses, open('models/dir_nrmses.pkl', 'wb'))\n",
    "pickle.dump(srs, open('models/dir_srs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrmses = pickle.load(open('models/dir_nrmses.pkl', 'rb'))\n",
    "srs = pickle.load(open('models/dir_srs.pkl', 'rb'))\n",
    "\n",
    "plt.xlabel('Original spectral radius')\n",
    "plt.ylabel('Evaluated NRMSE')\n",
    "\n",
    "plt.scatter(srs, nrmses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I see little/no correlation between the original spectral radius and the  \n",
    "evaluated NRMSE, so this is unlikely to be the culprit.  \n",
    "\n",
    "What about how the well-performing lattice _looks_?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plot import plot_lattice\n",
    "plot_lattice(dir_esn.G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With directedness: what is the distributions of in-degree/out-degree with  \n",
    "directed lattices? Can we color the lattices in some way to give insights?  \n",
    "\n",
    "An idea: what about average path length?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "esn.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
